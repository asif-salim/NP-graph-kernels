{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import scipy as sp\n",
    "import cupy as cp\n",
    "import csv\n",
    "import networkx as nx\n",
    "from sklearn import preprocessing\n",
    "from collections import OrderedDict\n",
    "import time "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inputs to be given\n",
    "dataset = 'SYNTHETICnew' # Choose the datasets among: 'PROTEINS', 'ENZYMES', 'BZR', 'COX2', 'DHFR', 'SYNTHETICnew'\n",
    "iter_num = 3 # No: of WL iteration\n",
    "ker = 1  # choose 0 for Gaussian kernel as base kernel and 1 for linear kernel\n",
    "path_to_data_folder = \"Datasets/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if dataset == 'PROTEINS':\n",
    "    A = np.loadtxt(path_to_data_folder + \"PROTEINS/PROTEINS_A.txt\", dtype = int, delimiter=\",\", unpack=False)\n",
    "    indicator = np.loadtxt(path_to_data_folder + \"PROTEINS/PROTEINS_graph_indicator.txt\", dtype = int, delimiter=\",\", unpack=False)\n",
    "    NL = np.loadtxt(path_to_data_folder + \"PROTEINS/PROTEINS_node_labels.txt\", dtype = int, delimiter=\",\", unpack=False)\n",
    "    NA = np.loadtxt(path_to_data_folder + \"PROTEINS/PROTEINS_node_attributes.txt\", dtype = float, delimiter=\",\", unpack=False)\n",
    "    EL = None\n",
    "    EA = None\n",
    "    \n",
    "if dataset == 'ENZYMES':\n",
    "    A = np.loadtxt(path_to_data_folder + \"ENZYMES/ENZYMES_A.txt\", dtype = int, delimiter=\",\", unpack=False)\n",
    "    indicator = np.loadtxt(path_to_data_folder + \"ENZYMES/ENZYMES_graph_indicator.txt\", dtype = int, delimiter=\",\", unpack=False)\n",
    "    NL = np.loadtxt(path_to_data_folder + \"ENZYMES/ENZYMES_node_labels.txt\", dtype = int, delimiter=\",\", unpack=False)\n",
    "    NA = np.loadtxt(path_to_data_folder + \"ENZYMES/ENZYMES_node_attributes.txt\", dtype = float, delimiter=\",\", unpack=False)\n",
    "    EL = None\n",
    "    EA = None\n",
    "    \n",
    "if dataset == 'BZR':\n",
    "    A = np.loadtxt(path_to_data_folder + \"BZR/BZR_A.txt\", dtype = int, delimiter=\",\", unpack=False)\n",
    "    indicator = np.loadtxt(path_to_data_folder + \"BZR/BZR_graph_indicator.txt\", dtype = int, delimiter=\",\", unpack=False)\n",
    "    NL = np.loadtxt(path_to_data_folder + \"BZR/BZR_node_labels.txt\", dtype = int, delimiter=\",\", unpack=False)\n",
    "    NA = np.loadtxt(path_to_data_folder + \"BZR/BZR_node_attributes.txt\", dtype = float, delimiter=\",\", unpack=False)\n",
    "    EL = None\n",
    "    EA = None\n",
    "    \n",
    "if dataset == 'COX2':\n",
    "    A = np.loadtxt(path_to_data_folder + \"COX2/COX2_A.txt\", dtype = int, delimiter=\",\", unpack=False)\n",
    "    indicator = np.loadtxt(path_to_data_folder + \"COX2/COX2_graph_indicator.txt\", dtype = int, delimiter=\",\", unpack=False)\n",
    "    NL = np.loadtxt(path_to_data_folder + \"COX2/COX2_node_labels.txt\", dtype = int, delimiter=\",\", unpack=False)\n",
    "    NA = np.loadtxt(path_to_data_folder + \"COX2/COX2_node_attributes.txt\", dtype = float, delimiter=\",\", unpack=False)\n",
    "    EL = None\n",
    "    EA = None\n",
    "    \n",
    "if dataset == 'DHFR':\n",
    "    A = np.loadtxt(path_to_data_folder + \"DHFR/DHFR_A.txt\", dtype = int, delimiter=\",\", unpack=False)\n",
    "    indicator = np.loadtxt(path_to_data_folder + \"DHFR/DHFR_graph_indicator.txt\", dtype = int, delimiter=\",\", unpack=False)\n",
    "    NL = np.loadtxt(path_to_data_folder + \"DHFR/DHFR_node_labels.txt\", dtype = int, delimiter=\",\", unpack=False)\n",
    "    NA = np.loadtxt(path_to_data_folder + \"DHFR/DHFR_node_attributes.txt\", dtype = float, delimiter=\",\", unpack=False)\n",
    "    EL = None\n",
    "    EA = None\n",
    "    \n",
    "if dataset == 'SYNTHETICnew':\n",
    "    A = np.loadtxt(path_to_data_folder + \"SYNTHETICnew/SYNTHETICnew_A.txt\", dtype = int, delimiter=\",\", unpack=False)\n",
    "    indicator = np.loadtxt(path_to_data_folder + \"SYNTHETICnew/SYNTHETICnew_graph_indicator.txt\", dtype = int, delimiter=\",\", unpack=False)\n",
    "    NL = None\n",
    "    NA = np.loadtxt(path_to_data_folder + \"SYNTHETICnew/SYNTHETICnew_node_attributes.txt\", dtype = float, delimiter=\",\", unpack=False)\n",
    "    EL = None\n",
    "    EA = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if NL is not None:\n",
    "    if len(NL.shape) == 1:\n",
    "        NL = np.reshape(NL,(NL.shape[0],1))\n",
    "if EL is not None:\n",
    "    if len(EL.shape) == 1:\n",
    "        EL = np.reshape(EL,(EL.shape[0],1))\n",
    "if len(NA.shape) == 1:\n",
    "    NA = np.reshape(NA,(NA.shape[0],1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_data(A, indicator, NA, EA=None, NL=None, EL=None):\n",
    "    U = np.unique(indicator)\n",
    "    count=[]\n",
    "    for i in range(U.shape[0]):\n",
    "        tmp = indicator[indicator==U[i]]\n",
    "        count.append(tmp.shape[0])\n",
    "    adj=[]\n",
    "    adj_list = []\n",
    "    node_label = []\n",
    "    node_attr = []\n",
    "    edge_list = []\n",
    "    edge_label = []\n",
    "    edge_attr= []\n",
    "    penalty = 0\n",
    "    p = 0\n",
    "    for i in range(len(count)):  \n",
    "        tmp = np.zeros((count[i], count[i]))\n",
    "        tmp_E = np.zeros((count[i], count[i]))\n",
    "        flag = 1\n",
    "        breakpoint = np.sum(count[0:i+1]) \n",
    "        tmp_EA = OrderedDict()\n",
    "        while flag==1: \n",
    "            if A[p,0]<=breakpoint and A[p,1]<=breakpoint:\n",
    "                A[p,0] = A[p,0] - 1\n",
    "                A[p,1] = A[p,1] - 1\n",
    "                tmp[A[p,0]-penalty,A[p,1]-penalty] = 1\n",
    "                \n",
    "                if EL is not None: \n",
    "                    tmp_E[A[p,0]-penalty,A[p,1]-penalty] = EL[p]\n",
    "                else:\n",
    "                    tmp_E[A[p,0]-penalty,A[p,1]-penalty] = 1\n",
    "                    \n",
    "                if EA is not None:  \n",
    "                    tmp_EA[str(A[p,0]-penalty)+str(A[p,1]-penalty)] = EA[p,:]\n",
    "                p=p+1 \n",
    "                if p == A.shape[0]:\n",
    "                    adj_list_tmp = []\n",
    "                    for j in range(tmp.shape[0]):\n",
    "                        adj_list_tmp.append(np.nonzero(tmp[j,:]))\n",
    "                        \n",
    "                    indx = np.nonzero(np.triu(tmp))   \n",
    "                    tmp1 = np.array((indx[0],indx[1]))\n",
    "                    edge_list.append(tmp1.T)\n",
    "                    \n",
    "                    if NL is not None:\n",
    "                        node_label.append(NL[penalty:breakpoint,0])\n",
    "                    else:\n",
    "                        node_label.append(np.ones(([breakpoint-penalty,1])))\n",
    "                    node_attr.append(NA[penalty:breakpoint,:])\n",
    "                    adj_list.append(adj_list_tmp) \n",
    "                    edge_label.append(tmp_E[indx[0],indx[1]])\n",
    "                    if EA is not None:\n",
    "                        edge_attr.append(tmp_EA) \n",
    "                    del tmp, tmp_E\n",
    "                    flag=0\n",
    "                    \n",
    "            else:\n",
    "                \n",
    "                adj_list_tmp = []\n",
    "                for j in range(tmp.shape[0]):\n",
    "                    adj_list_tmp.append(np.nonzero(tmp[j,:]))\n",
    "                    \n",
    "                \n",
    "                indx = np.nonzero(np.triu(tmp)) \n",
    "                tmp1 = np.array((indx[0],indx[1]))\n",
    "                edge_list.append(tmp1.T)\n",
    "                \n",
    "                if NL is not None:\n",
    "                    node_label.append(NL[penalty:breakpoint,0])\n",
    "                else:\n",
    "                    \n",
    "                    node_label.append(np.ones(([breakpoint-penalty,1])))\n",
    "                node_attr.append(NA[penalty:breakpoint,:])\n",
    "                adj_list.append(adj_list_tmp) \n",
    "                edge_label.append(tmp_E[indx[0],indx[1]])\n",
    "                if EA is not None:\n",
    "                        edge_attr.append(tmp_EA) \n",
    "                del tmp, tmp_E\n",
    "                flag = 0 \n",
    "        flag = 1\n",
    "        penalty = breakpoint  \n",
    "    return adj_list, node_label, node_attr, edge_list, edge_label, edge_attr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "adj_list, NL_list, NA_list, E_list, EL_list, EA_list = create_data(A, indicator, NA,EA, NL, EL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def WL_refinement(adj_list, NL_list):\n",
    "    WL_list=[]\n",
    "    od = OrderedDict()\n",
    "    p = 0\n",
    "    for i in range(0, len(adj_list)):\n",
    "        WL_tmp=[]\n",
    "        for j in range(0,len(adj_list[i])):\n",
    "            tmp = np.sort(NL_list[i][adj_list[i][j]])\n",
    "            tmp = ''.join(str(x) for x in tmp) \n",
    "            label = str(NL_list[i][j])+tmp\n",
    "            if label in od:\n",
    "                WL_tmp.append(od[label])\n",
    "            else:\n",
    "                od[label] = p\n",
    "                WL_tmp.append(p)\n",
    "                p+=1\n",
    "        WL_list.append(np.asarray(WL_tmp))\n",
    "    return WL_list,p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def kernel_pair_computation(od1,od2, NA1, NA2, odEA1, odEA2, ker, beta1, beta2):\n",
    "                const = []\n",
    "                \n",
    "                st1, st2 = set(od1), set(od2)\n",
    "                \n",
    "                common_keys = st1.intersection(st2)\n",
    "                T1, T2 = np.zeros((0)), np.zeros((0))\n",
    "                tmp11, tmp12, tmp21, tmp22 = np.zeros((0)), np.zeros((0)), np.zeros((0)), np.zeros((0))\n",
    "                tmpE1, tmpE2 = np.zeros((0,beta2)), np.zeros((0,beta2))  \n",
    "                oea = 0\n",
    "                kt=0\n",
    "                for k in common_keys:\n",
    "                    lst1,lst2 = od1[k], od2[k]  \n",
    "                    oea += min(len(lst1), len(lst2))\n",
    "                    if odEA1 != None:\n",
    "                        EAlst1, EAlst2= [],[] \n",
    "                        for m in range(len(lst1)):\n",
    "                            c = str(lst1[m][0])+str(lst1[m][1])\n",
    "                            EAlst1.append(odEA1[c])\n",
    "                        for m in range(len(lst2)):\n",
    "                            c = str(lst2[m][0])+str(lst2[m][1])\n",
    "                            EAlst2.append(odEA2[c])\n",
    "                        EAlst1=np.asarray(EAlst1)\n",
    "                        EAlst2=np.asarray(EAlst2) \n",
    "                        EAlst1, EAlst2 = np.repeat(EAlst1, len(EAlst2), axis=0), np.tile(EAlst2,(len(EAlst1),1))   \n",
    "                        tmpE1 = np.concatenate((tmpE1,EAlst1), axis=0)\n",
    "                        tmpE2 = np.concatenate((tmpE2,EAlst2), axis=0)\n",
    "                        \n",
    "                    lst1,lst2 = np.asarray(lst1, dtype = np.int32), np.asarray(lst2, dtype = np.int32)  \n",
    "                    lst1, lst2 = np.repeat(lst1, len(lst2), axis=0), np.tile(lst2,(len(lst1),1))  \n",
    "                    const.append([1/lst1.shape[0]]*lst1.shape[0])\n",
    "                    tmp11 = np.concatenate((tmp11,lst1[:,0]), axis=0)\n",
    "                    tmp12 = np.concatenate((tmp12,lst2[:,0]), axis=0)              \n",
    "                    tmp21 = np.concatenate((tmp21,lst1[:,1]), axis=0)\n",
    "                    tmp22 = np.concatenate((tmp22,lst2[:,1]), axis=0)  \n",
    "                    \n",
    "                if len(common_keys)!=0:\n",
    "                    const = np.hstack(const)  \n",
    "                    N11, N12 = NA1[tmp11.astype(int)], NA2[tmp12.astype(int)]   \n",
    "                    N21, N22 = NA1[tmp21.astype(int)], NA2[tmp22.astype(int)]  \n",
    "                    N11, N12, N21, N22, const = cp.asarray(N11),cp.asarray(N12),cp.asarray(N21),cp.asarray(N22),cp.asarray(const)\n",
    "                    if ker==0:\n",
    "                        t1 =  cp.exp(-1/beta1*(np.linalg.norm((N11-N12),axis=1)**2)) \n",
    "                        t2 =  cp.exp(-1/beta1*(np.linalg.norm((N21-N22),axis=1)**2))   \n",
    "                        t = cp.multiply(const,t1)\n",
    "                        t = cp.multiply(t, t2)   \n",
    "                        if len(EA_list)!=0:\n",
    "                            t = cp.multiply(t, np.exp(-1/beta2*(np.linalg.norm((tmpE1-tmpE2),axis=1)**2)))\n",
    "                        t = cp.sum(t) \n",
    "                         \n",
    "                    else:\n",
    "                        t1 =  cp.multiply(N11,N12) \n",
    "                        t1 = cp.sum(t1,axis = 1)\n",
    "                        t2 =  cp.multiply(N21,N22) \n",
    "                        t2 = cp.sum(t2,axis = 1) \n",
    "                        t = cp.multiply(const, t1)\n",
    "                        t = cp.multiply(t, t2)\n",
    "                        if odEA1 != None:\n",
    "                            t1 = cp.multiply(tmpE1, tmpE2)\n",
    "                            t1= cp.sum(t1, axis = 1)\n",
    "                            t = cp.multiply(t, t1)\n",
    "                        t = cp.sum(t)  \n",
    "                else:\n",
    "                    t=0 \n",
    "                return t,oea"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def NP_kernel_imp2(adj_list, NL_list, NA_list, E_list, EL_list, EA_list, h, ker): \n",
    "    KM_npe, KM_oea = [],[]\n",
    "    beta1 = NA_list[0].shape[1]\n",
    "    beta2= 1\n",
    "    if len(EA_list)!=0:\n",
    "        beta2 = EA.shape[1]\n",
    "    for f in range(h):\n",
    "        K_npe = np.zeros((len(adj_list), len(adj_list))) \n",
    "        K_oea = np.zeros((len(adj_list), len(adj_list))) \n",
    "        WL_list, label_count = WL_refinement(adj_list, NL_list)\n",
    "        print(\"WL labels in iteration:{} = {}\".format(f,label_count))\n",
    "        WL_tmp=[]\n",
    "        WL_ref_add = [] \n",
    "        for j in range(len(E_list)): \n",
    "            od = OrderedDict()\n",
    "            for k in range(len(E_list[j])): \n",
    "                tmp = E_list[j][k,:]\n",
    "                tmp = tmp.tolist()\n",
    "                tmp2 = [WL_list[j][tmp[0]], WL_list[j][tmp[1]]] \n",
    "                args = np.argsort(tmp2)\n",
    "                tmp2  = [tmp2[args[0]] ,tmp2[args[1]] ]\n",
    "                if args[0]!=0:\n",
    "                    tmp =tmp[::-1]  \n",
    "                label1  = tmp2 + [int(EL_list[j][k])]\n",
    "                tmp2 = tmp2[::-1]\n",
    "                label2 = tmp2 + [int(EL_list[j][k])]\n",
    "                label1, label2 = ' '.join(str(x) for x in label1), ' '.join(str(x) for x in label2)  \n",
    "                if label1 not in od and label2 not in od:\n",
    "                    od[label1]=[]\n",
    "                if label1 in od:\n",
    "                    od[label1].append(tmp)\n",
    "                if label2 in od and label2!=label1:\n",
    "                    tmp = tmp[::-1]\n",
    "                    od[label2].append(tmp)\n",
    "            \n",
    "            WL_ref_add.append(od) \n",
    "        NL_list = WL_list  \n",
    "        for i in range(len(E_list)): \n",
    "            od1 = WL_ref_add[i] \n",
    "            NA1 = NA_list[i]\n",
    "            if len(EA_list)!=0:\n",
    "                odEA1 = EA_list[i]\n",
    "            else:\n",
    "                odEA1 = None \n",
    "            for j in range(len(E_list)): \n",
    "                if i<=j:\n",
    "                    od2 =  WL_ref_add[j]  \n",
    "                    NA2 =  NA_list[j]\n",
    "                    if len(EA_list)!=0:\n",
    "                        odEA2 = EA_list[j]\n",
    "                    else:\n",
    "                        odEA2 = None\n",
    "                    t, oea = kernel_pair_computation(od1,od2, NA1, NA2, odEA1, odEA2, ker, beta1, beta2)\n",
    "                    K_npe[i,j],K_npe[j,i] =  t, t\n",
    "                    K_oea[i,j],K_oea[j,i] =  oea, oea\n",
    "                \n",
    "        KM_npe.append(K_npe)    \n",
    "        KM_oea.append(K_oea)\n",
    "    return KM_npe, KM_oea, WL_ref_add"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "\n",
    "KM_npe, KM_oea, WL = NP_kernel_imp2( adj_list, NL_list, NA_list, E_list, EL_list,EA_list, iter_num, ker)\n",
    "end = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Time taken (in seconds): {}\".format(end - start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
